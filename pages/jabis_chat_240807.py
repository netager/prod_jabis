import streamlit as st
from langchain_core.messages.chat import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate

from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatOllama
from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain_core.callbacks.manager import CallbackManager

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma


from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import load_prompt
from langchain import hub
from dotenv import load_dotenv

from langchain_teddynote import logging
from time import time
import base64
from streamlit_pdf_viewer import pdf_viewer


# .env í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
# ----------------
# load_dotenv()


# LangSmithë¥¼ ì´ìš©í•˜ì—¬ LLM ì¶”ì 
# -------------------------
# logging.langsmith("PROD_LLM", set_enable=True)  # enable



# -----------------------------------------------------------------------------
# Embedding Model Caching
# -----------------------------------------------------------------------------
# Caching Embedding Model
# -----------------------
# model_name_path = '../embedding_model/KR-SBERT-V40K-klueNLI-augSTS'
model_name_path = '../embedding_model/BAAI_bge-m3'

@st.cache_resource()
def embeddings_call():

    return HuggingFaceEmbeddings(
        model_name=model_name_path, 
        model_kwargs={"device": "mps"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'
        # ëª¨ë¸ì´ CPUì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì„¤ì •. GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì´ë¼ë©´ 'cuda'ë¡œ ì„¤ì •í•  ìˆ˜ë„ ìˆìŒ
        encode_kwargs={
            "normalize_embeddings": True
        },  # ì„ë² ë”© ì •ê·œí™”. ëª¨ë“  ë²¡í„°ê°€ ê°™ì€ ë²”ìœ„ì˜ ê°’ì„ ê°–ë„ë¡ í•¨. ìœ ì‚¬ë„ ê³„ì‚° ì‹œ ì¼ê´€ì„±ì„ ë†’ì—¬ì¤Œ
        # cache_folder='../embedding/model',
    )

# -----------------------------------------------------------------------------
# í•¨ìˆ˜ Define
# -----------------------------------------------------------------------------
# pdf ì¶œë ¥ì„ ìœ„í•œ í•¨ìˆ˜
# ----------------
def displayPDF(file, page):
    # Opening file from file path
    with open(file, "rb") as f:
        base64_pdf = base64.b64encode(f.read()).decode('utf-8')

    # Embedding PDF in HTML
    # pdf_display = F'<iframe src="data:application/pdf;base64,{base64_pdf}" width="700" height="650" type="application/pdf"></iframe>'
    pdf_display = F'<iframe src="data:application/pdf;base64,{base64_pdf}#page={page}" width="100%" height="750" type="application/pdf"></iframe>'    
    # pdf_display = F'<embed src="data:application/pdf;base64,{base64_pdf}" width="700" height="700" type="application/pdf">'
    # pdf_display = F'<iframe src="{file}#toolbar=0 page={page}"></iframe>'
    # Displaying File
    # return pdf_display
    st.markdown(pdf_display, unsafe_allow_html=True)


# ì„¸ì…˜ì— ì €ì¥ëœ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
# ---------------------------------
def print_saved_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)


# ì„¸ì…˜ì— ëŒ€í™” ë‚´ìš© ì €ì¥í•˜ëŠ”ë° ChatMessage í˜•ì‹ìœ¼ë¡œ ì €ì¥
# -------------------------------------------
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))



# ì²´ì¸ ìƒì„± í•¨ìˆ˜
def create_chain(prompt_type, user_input):
    # RAG Prompt
    if prompt_type == "ì€í–‰ì—…ë¬´ ì§ˆì˜":
        prompt = load_prompt("./prompts/rag.yaml")

    # í”„ë¡¬í”„íŠ¸(ê¸°ë³¸ëª¨ë“œ)
    else:
        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "ë‹¹ì‹ ì€ ì¹œì ˆí•œ 20ë…„ì°¨ ì€í–‰ì›ì´ë©´ì„œ IT ì „ë¬¸ê°€ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.",
                ),
                ("user", """#Question:\n{question}
                            #Answer:\n """),
            ]
        )

    embeddings = embeddings_call()

    # Chroma db Loading
    chroma_db = Chroma(persist_directory="../Chroma_db/chroma_bank_law_db", 
                       embedding_function=embeddings, 
                       collection_name="bank_law_case")

    # chroma_docs = chroma_db.similarit
    # y_search_with_score(user_input, k=3)
    search_results = chroma_db.similarity_search_with_score(user_input, k=3)

    # Retriever ì •ì˜
    retriever = chroma_db.as_retriever(search_type="similarity", search_kwargs={"k": 1})

    # LLM ëª¨ë¸ ì„ íƒ
    # -----------
    # llm = ChatOllama(model="EEVE-Korean-10.8B:latest", temperature=0,)
    # llm = ChatOllama(model="sh2orc-Llama-3.1-Korean-8B-Instruct_q8_0", temperature=0,)
    # llm = ChatOllama(model="sh2orc-Llama-3.1-Korean-8B-Instruct_q8_1", temperature=0,)
    llm = ChatOllama(model="sh2orc-Llama-3.1-Korean-8B-Instruct_q8_2", temperature=0,)

    # llm = ChatOllama(model="Llama-3-BCCard-Kor-8B-q8-0:latest", temperature=0,)
    # llm = ChatOllama(model="Llama-3-Open-Ko-8B-Q8:latest", temperature=0)    
    # llm = ChatOllama(model="qwen2-7b-instruct-q8:latest", temperature=0)    
    # llm = ChatOllama(model="llama3:instruct", temperature=0,)
    # llm = ChatOpenAI(model_name="gpt-4o", temperature=0,)
    # llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0,)

    # ì¶œë ¥ íŒŒì„œ
    output_parser = StrOutputParser()

    # ì²´ì¸ ìƒì„±
    if prompt_type == "ì€í–‰ì—…ë¬´ ì§ˆì˜":
        chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | output_parser
        )
    else:

        chain = (
            prompt
            | llm
            | output_parser
        )
    # chain = prompt | llm | output_parser

    return chain, search_results

# ì²«ì¸ì‚¬ í•˜ê¸°
def greeting():    
    import random
    initial_messages = ["ì•ˆë…•í•˜ì„¸ìš”. ë§Œë‚˜ëµ™ê²Œ ë˜ì–´ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì €ëŠ” ì „ë¶ì€í–‰ì—ì„œ ê·¼ë¬´í•˜ëŠ” Chat ìƒë‹´ì› Jabisì…ë‹ˆë‹¤.\n\n ì™¼ìª½ ë©”ë‰´ì˜ [í™œìš© ì—…ë¬´ ì„ íƒ]ì„ í™•ì¸í•˜ê³  ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ë©´ ì•„ë˜ì— ì…ë ¥í•´ ì£¼ì„¸ìš”.",
                        "ì•ˆë…•í•˜ì„¸ìš”. ë§Œë‚˜ëµ™ê²Œ ë˜ì–´ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì €ëŠ” ì „ë¶ì€í–‰ì—ì„œ ê·¼ë¬´í•˜ëŠ” Chat ìƒë‹´ì› Jabisì…ë‹ˆë‹¤.\n\n ì™¼ìª½ ë©”ë‰´ì˜ [í™œìš© ì—…ë¬´ ì„ íƒ]ì„ í™•ì¸í•˜ê³  ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ë©´ ì•„ë˜ì— ì…ë ¥í•´ ì£¼ì„¸ìš”.",
                    ]

    random_number = random.randint(0, len(initial_messages) - 1)
    return initial_messages[random_number]


if 'sbstate' not in st.session_state:
    st.session_state.sbstate = 'collapsed'


with st.sidebar:
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")
    selected_prompt = st.selectbox("í™œìš© ì—…ë¬´ ì„ íƒ ", ("ì€í–‰ì—…ë¬´ ì§ˆì˜", "ì¼ë°˜ ì§ˆì˜"), index=0)


# Header ì¶œë ¥
# ----------
head_col1, head_col2 = st.columns([0.9, 0.1], gap="large", vertical_alignment="center")
head_col1.subheader('ğŸ’¬ :blue[JABIS(_Jb Ai Business Information System_)]', divider='rainbow', anchor=None, help=None)
# head_col1.header('ğŸ’¬ :blue[JABIS(_JBB Office ChatBot_)]', divider='rainbow', anchor=None, help=None)
head_col2.page_link("jabis.py", label="Home", icon="ğŸ ")

# ëŒ€í™”ë‚´ìš© ì €ì¥ ê³µê°„ ì •ì˜
# -----------------------
if "messages" not in st.session_state:
    # ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ìƒì„±í•œë‹¤.
    st.session_state["messages"] = []

    # ì²«ì¸ì‚¬ ì²˜ë¦¬
    #------------
    greeting_message = greeting()
    
    st.chat_message("assistant").markdown(greeting_message)    

if clear_btn:
    st.session_state["messages"] = []


# ì„¸ì…˜ì— ì €ì¥ëœ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í™”ë©´ì— ì¶œë ¥
# qa_container = st.container(height=700)    

for chat_message in st.session_state["messages"]:
    st.chat_message(chat_message.role).write(chat_message.content)

# ì‚¬ìš©ìì˜ ì…ë ¥
user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ë§Œì•½ì— ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´
if user_input:
    # ì‚¬ìš©ìì˜ ì…ë ¥
    st.chat_message("user").write(user_input)

    # chain, document_source, document_page = create_chain(selected_prompt, user_input)
    chain, search_results = create_chain(selected_prompt, user_input)

    # # í™”ë©´ì— ë¡œê¹…
    # st.info("íŒŒì¼ëª…: " + document_source + "\ní˜ì´ì§€: " + str(document_page))    

    # PDF ì¶œë ¥ 
    # if(selected_prompt == "ì€í–‰ì—…ë¬´ ì§ˆì˜"):
    #     with column_pdf:
    #         displayPDF(document_source, document_page)
    #         st.info("íŒŒì¼ëª…: " + document_source + "\ní˜ì´ì§€: " + str(document_page))    


    # ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
    # response = chain.stream({"question": user_input})
    response = chain.stream(user_input)

    with st.chat_message("assistant"):
        # ë¹ˆ ê³µê°„(ì»¨í…Œì´ë„ˆ)ì„ ë§Œë“¤ì–´ì„œ, ì—¬ê¸°ì— í† í°ì„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ í•œë‹¤.
        container = st.empty()

        ai_answer = ""
        for token in response:
            ai_answer += token
            container.markdown(ai_answer)
            # container.write(ai_answer)

        # st.write(len(search_results))
        # for search_result in search_results:
        #     st.write(search_result.score)
        #     st.write(search_result.metadata['page'])

        if selected_prompt == "ì€í–‰ì—…ë¬´ ì§ˆì˜":
            # í–¥í›„ ë¬¸ì„œ ë° í˜ì´ì§€ ì¤‘ë³µì‹œ ì¤‘ë³µ ì œê±°
            # ------------------------------------
            # test_list = set([(search_result[0].metadata['source'], search_result[0].metadata['page']) for search_result in search_results])
            # st.write(test_list)

            linked_docs = ""
            for search_result in search_results:
            
                # st.write(search_result[1])
                # st.write(search_result[0].metadata['page']+1)

                # linked_docs += f"[{search_result[0].metadata['source']}](http://localhost:8501/jabis_pdf_view?doc_name='{search_result[0].metadata['source']}'&page={search_result[0].metadata['page']})\n\n"

                # linked_docs += f"[{search_result[0].metadata['source']}](http://localhost:8501/jabis_pdf_view?doc_name=ab c&page=1)\n\n"
                # linked_docs += f"['[Naver]()'](http://localhost:8501/jabis_pdf_view?abc=111&page=10)\n\n"

                from urllib.parse import urlencode
                # base_url = 'http://192.168.50.70:8080/jabis_pdf_view'
                base_url = 'http://localhost:8080/jabis_pdf_view'
                params = {
                'source': search_result[0].metadata['source'],
                # 'title': search_result[0].metadata['title'],
                'title': search_result[0].metadata['source'],
                'page': search_result[0].metadata['page']+1
                }
                url_with_params = base_url + '?' + urlencode(params)


                # st.markdown(
                #     f'''<a href="{app_path}/{page}?abc=123" target="_self">goto page 1</a>''',
                #     unsafe_allow_html=True
                # )


                # linked_docs += f"[{search_result[0].metadata['source']}]({url_with_params}) ~ params['page']\n\n"

                # ì¤‘ë³µ ì œê±°
                # ---------
                linked_docs += f"ğŸ‘‰ [{params['title']}]({url_with_params}) ~ <pages : {params['page']}> <{round(search_result[1],3)}>\n\n"

                # app_path = 'http://localhost:8501'
                # page_file_path = 'pages/page1.py'
                # page = page_file_path.split('/')[1][0:-3]  # get "page1"
                # linked_docs += f'''<a href="{app_path}/page1?abc=123" target="_self">goto page 1</a>'''
                # st.write(search_result[0].metadata['source'])
                # st.write(search_result[0].metadata['page']+1)

                # from urllib.parse import urlencode
                # base_url = 'http://localhost:8501/jabis_pdf_view'
                # params = {
                # 'category': './data/jbb/á„€á…²á„Œá…¥á†¼/á„‡á…§á†¯á„Œá…µ 1 á„€á…©á†¼á„€á…©á†¼ á„†á…¡á„‹á…µá„ƒá…¦á„‹á…µá„á…¥ á„’á…ªá†¯á„‹á…­á†¼ á„ƒá…©á†¼á„‹á…´á„‰á…¥(2024. 2. 1 á„€á…¢á„Œá…¥á†¼).pdf',
                # 'page': 1
                # }    
                # url_with_params = base_url + '?' + urlencode(params)
                
                # page_link(f'http://localhost:8501/jabis_pdf_view?{}', label='Jabis Chat')
            ai_answer = ai_answer + "\n\n ğŸ“– ê´€ë ¨ ë¬¸ì„œ ë³´ê¸°\n\n" + linked_docs

            container.markdown(ai_answer, unsafe_allow_html=True)


    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
    add_message("user", user_input)
    add_message("assistant", ai_answer)


# if st.button("Return to Main"):
#     st.session_state.runpage = Page_Main
#     # st.experimental_rerun()
#     st.rerun()