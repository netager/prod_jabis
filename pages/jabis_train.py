
import streamlit as st

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

from dotenv import load_dotenv
import os
from datetime import datetime

# ì²˜ë¦¬ì‹œê°„ í™•ì¸
# ----------
def get_cur_time():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

LOG_STATUS = "CONSOLE"
def log_writer(LOG_STATUS, message):
    if LOG_STATUS == "CONSOLE_MONITOR":
        st.write(f"[{get_cur_time()}] {message}")
        print(f"[{get_cur_time()}] {message}")
    elif LOG_STATUS == "CONSOLE":
        print(f"[{get_cur_time()}] {message}")
    elif LOG_STATUS == "MONITOR":
        st.write(f"[{get_cur_time()}] {message}")

log_writer(LOG_STATUS, "(Local_RAG.py) Local_RAG Program Start")

# API KEY ì •ë³´ë¡œë“œ
load_dotenv()


model_name_path = "../../HUGGING_FACE_MODEL/BAAI_bge-m3"
@st.cache_resource()
def embeddings_call():
    return HuggingFaceEmbeddings(
        model_name=model_name_path,
        model_kwargs={"device": "mps"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'
        # ëª¨ë¸ì´ CPUì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì„¤ì •. GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì´ë¼ë©´ 'cuda'ë¡œ ì„¤ì •í•  ìˆ˜ë„ ìˆìŒ
        encode_kwargs={
            "normalize_embeddings": True
        },  # ì„ë² ë”© ì •ê·œí™”. ëª¨ë“  ë²¡í„°ê°€ ê°™ì€ ë²”ìœ„ì˜ ê°’ì„ ê°–ë„ë¡ í•¨. ìœ ì‚¬ë„ ê³„ì‚° ì‹œ ì¼ê´€ì„±ì„ ë†’ì—¬ì¤Œ
        # cache_folder='../embedding/model',
    )


def vectorize_file(uploaded_fiels):
    for uploaded_file in uploaded_files:
        file_content = uploaded_file.read()
        file_path = f"../rag_data/user_train_files/{uploaded_file.name}"
        with open(file_path, "wb") as f:
            f.write(file_content)

        # ë‹¨ê³„ 1: ë¬¸ì„œ ë¡œë“œ(Load Documents)
        st.markdown(f'[{get_cur_time()}] {uploaded_file.name}ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤.')
        loader = PyPDFLoader(file_path)
        docs = loader.load()

        # ë‹¨ê³„ 2: ë¬¸ì„œ ë¶„í• (Split Documents)
        st.markdown(f'[{get_cur_time()}] {uploaded_file.name}ì„ ë¶„í• í•˜ê³  ìˆìŠµë‹ˆë‹¤.')
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=0)
        split_documents = text_splitter.split_documents(docs)

        # ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±
        embeddings = embeddings_call()

        # ë‹¨ê³„ 4: DB ìƒì„±(Create DB) ë° ì €ì¥
        st.markdown(f'[{get_cur_time()}] {uploaded_file.name}ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.')
        # ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        # vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)
        # vectorstore = Chroma.from_documents(documents=split_documents, embedding=embeddings, persist_directory="./Chroma_DB/chroma_bank_law_db",
        Chroma.from_documents(documents=split_documents, embedding=embeddings)
        st.markdown(f'---')


# ì²˜ë¦¬ì‹œê°„ í™•ì¸
# -------------
def get_cur_time():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# í•™ìŠµ ëŒ€ìƒ í´ë” ìƒì„±
# -------------------
def create_rag_file_store():
    # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists("../rag_data"):
        os.mkdir("../rag_data")

    # íŒŒì¼ ì—…ë¡œë“œ ì „ìš© í´ë”
    if not os.path.exists("../rag_data/user_train_files"):
        os.mkdir("../rag_data/user_train_files")

create_rag_file_store()

# í—¤ë” ì¶œë ¥
# ---------
head_col1, head_col2 = st.columns([0.9, 0.1], gap="large", vertical_alignment="center")
head_col1.subheader(
    ":blue[Jabis í•™ìŠµí•˜ê¸° ğŸ“š]",
    divider="rainbow",
    anchor=None,
    help=None,
)
head_col2.page_link("jabis.py", label="Home", icon="ğŸ ")


# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader("í•™ìŠµ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=["pdf"], accept_multiple_files=True)

# íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆì„ ë•Œ
# -----------------------
if uploaded_files:
    st.markdown(f'[{get_cur_time()}] Jabis í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.')
    st.markdown(f'---')
    log_writer(LOG_STATUS, "(Local_RAG.py) vectorize_file Start")
    vectorize_file(uploaded_files)

    log_writer(LOG_STATUS, "(Local_RAG.py) íŒŒì¼ í•™ìŠµ ì¢…ë£Œ")
    st.markdown(f'[{get_cur_time()}] Jabis í•™ìŠµì„ ì •ìƒ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.')