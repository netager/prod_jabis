
import streamlit as st

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document

from dotenv import load_dotenv
import os
import re
from datetime import datetime

# ì²˜ë¦¬ì‹œê°„ í™•ì¸
# ----------
def get_cur_time():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

LOG_STATUS = "CONSOLE"
def log_writer(LOG_STATUS, message):
    if LOG_STATUS == "CONSOLE_MONITOR":
        st.write(f"[{get_cur_time()}] {message}")
        print(f"[{get_cur_time()}] {message}")
    elif LOG_STATUS == "CONSOLE":
        print(f"[{get_cur_time()}] {message}")
    elif LOG_STATUS == "MONITOR":
        st.write(f"[{get_cur_time()}] {message}")

log_writer(LOG_STATUS, "(Local_RAG.py) Local_RAG Program Start")

# API KEY ì •ë³´ë¡œë“œ
load_dotenv()

# í•™ìŠµ ëŒ€ìƒ í´ë” ìƒì„±
# -------------------
TRAIN_FILES = "../rag_data/user_train_files"
if not os.path.exists(TRAIN_FILES):
    os.makedirs(TRAIN_FILES)


model_name_path = "../HUGGING_FACE_MODEL/BAAI_bge-m3"
@st.cache_resource()
def embeddings_call():
    return HuggingFaceEmbeddings(
        model_name=model_name_path,
        model_kwargs={"device": "mps"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'
        # ëª¨ë¸ì´ CPUì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì„¤ì •. GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì´ë¼ë©´ 'cuda'ë¡œ ì„¤ì •í•  ìˆ˜ë„ ìˆìŒ
        encode_kwargs={
            "normalize_embeddings": True
        },  # ì„ë² ë”© ì •ê·œí™”. ëª¨ë“  ë²¡í„°ê°€ ê°™ì€ ë²”ìœ„ì˜ ê°’ì„ ê°–ë„ë¡ í•¨. ìœ ì‚¬ë„ ê³„ì‚° ì‹œ ì¼ê´€ì„±ì„ ë†’ì—¬ì¤Œ
        # cache_folder='../embedding/model',
    )


def vectorize_file(uploaded_fiels):
    for uploaded_file in uploaded_files:
        file_content = uploaded_file.read()
        file_path = f"{TRAIN_FILES}/{uploaded_file.name}"
        with open(file_path, "wb") as f:
            f.write(file_content)

        # ë‹¨ê³„ 1: ë¬¸ì„œ ë¡œë“œ(Load Documents)
        st.markdown(f'[{get_cur_time()}] {uploaded_file.name}ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤.')
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        st.markdown(f'[{get_cur_time()}] {uploaded_file.name} í˜ì´ì§€ ìˆ˜: {len(docs)}')

        # ë‹¨ê³„ 2: ë¬¸ì„œ ë¶„í• (Split Documents)
        st.markdown(f'[{get_cur_time()}] {uploaded_file.name}ì„ ë¶„í• í•˜ê³  ìˆìŠµë‹ˆë‹¤.')
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=0)
        split_documents = text_splitter.split_documents(docs)
        st.markdown(f'[{get_cur_time()}] {uploaded_file.name} í˜ì´ì§€ ìˆ˜: {len(docs)}, ë¶„í• í•œ ë¬¸ì„œì˜ ìˆ˜: {len(split_documents)}')

        ## ì¼ë¶€ í•„ìš”í•œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• ëœ ë¬¸ì„œì— ì¶”ê°€ ë° ë¶ˆí•„ìš”í•œ ë¬¸ì ì‚­ì œ
        final_docs = []

        # ë¬¸ì„œë§Œ ë³´ì—¬ì£¼ê¸° ìœ„í•œ Document ê°ì²´ ìƒì„± ë° ì €ì¥
        contents = ['ë³´ì—¬ì¤˜', 'ì•Œë ¤ì¤˜']
        for content in contents:
            title = os.path.splitext(file_path)[0].split('/')[-1]    # íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
            doc = Document(page_content = f"ì „ë¶ì€í–‰ {title} {content}")
            doc.metadata['title'] = title        
            doc.metadata['source'] = file_path
            doc.metadata['page'] = 0
            
            final_docs.append(doc)

        doc_cnt = len(final_docs)   # ë¬¸ì„œë§Œ ë³´ì—¬ì£¼ê¸°ìœ„í•œ ë¬¸ì„œ ìˆ˜ 

        for doc in split_documents:
            title = os.path.splitext(doc.metadata['source'])[0].split('/')[-1]
            doc.page_content = (
                re.sub(r"(?<!\.)\n", " ", doc.page_content)
                + f"\n\në¬¸ì„œ : ì „ë¶ì€í–‰ {title}"        
            )
            doc.metadata['title'] = title
            final_docs.append(doc)

        st.markdown(f'[{get_cur_time()}] {uploaded_file.name} ë¶„í• í•œ ë¬¸ì„œì˜ ìˆ˜: {len(split_documents)}, ë³´ì—¬ì£¼ê¸°ìœ„í•œ ë¬¸ì„œìˆ˜: {doc_cnt}, ì²˜ë¦¬í•  ì´ ë¬¸ì„œì˜ ìˆ˜: {len(final_docs)}')

        # ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±
        embeddings_model = embeddings_call()

        # ë‹¨ê³„ 4: DB ìƒì„±(Create DB) ë° ì €ì¥
        st.markdown(f'[{get_cur_time()}] {uploaded_file.name}ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.')
        # ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        # vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)
        # vectorstore = Chroma.from_documents(documents=split_documents, embedding=embeddings, persist_directory="./Chroma_DB/chroma_bank_law_db",
        Chroma.from_documents(documents=split_documents, embedding=embeddings_model,
                                collection_name="bank_law_case",)

        # Chroma.from_documents(documents=split_documents, embedding=embeddings_model,
        #                         persist_directory="../Chroma_DB/chroma_bank_law_db",
        #                         collection_name="bank_law_case",)
        st.markdown(f'---')


# ì²˜ë¦¬ì‹œê°„ í™•ì¸
# -------------
def get_cur_time():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# í—¤ë” ì¶œë ¥
# ---------
head_col1, head_col2 = st.columns([0.9, 0.1], gap="large", vertical_alignment="center")
head_col1.subheader(
    ":blue[Jabis í•™ìŠµí•˜ê¸° ğŸ“š]",
    divider="rainbow",
    anchor=None,
    help=None,
)
head_col2.page_link("jabis.py", label="Home", icon="ğŸ ")


# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader("í•™ìŠµ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=["pdf"], accept_multiple_files=True)

# íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆì„ ë•Œ
# -----------------------
if uploaded_files:
    st.markdown(f'[{get_cur_time()}] Jabis í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.')
    st.markdown(f'---')
    log_writer(LOG_STATUS, "(Local_RAG.py) vectorize_file Start")
    vectorize_file(uploaded_files)

    log_writer(LOG_STATUS, "(Local_RAG.py) íŒŒì¼ í•™ìŠµ ì¢…ë£Œ")
    st.markdown(f'[{get_cur_time()}] Jabis í•™ìŠµì„ ì •ìƒ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.')