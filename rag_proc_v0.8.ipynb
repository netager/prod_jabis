{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통합본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "[2024-08-22 11:21:47] 1단계 : 임베딩할 파일 지정 및 텍스트 문서로 변환\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "[2024-08-22 11:24:41] 파일의 전체 갯수 : 463, 파일의 전체 페이지 수: 6122\n",
      "----------------------------------------------------------------------\n",
      "[2024-08-22 11:24:59] PDF 문서의 페이지 수: 6122, 분할한 문서의 수: 17196\n",
      "[2024-08-22 11:24:59] 분할한 문서의 수: 17196, 보여주기위한 문서수: 1389, 처리할 총 문서의 수: 18585\n",
      "[2024-08-22 11:24:59] 벡터 스토어 저장 Start ...\n",
      "[2024-08-22 11:27:20] Chroma DB 에 저장된 총 건수: 10000\n",
      "[2024-08-22 11:29:34] Chroma DB 에 저장된 총 건수: 18585\n",
      "[2024-08-22 11:29:34] 문서 임베딩이 완료 되었습니다\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# from tqdm.autonotebook import tqdm, trange\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_cur_time():\n",
    "    return datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Embedding 모델 정의\n",
    "# -----------------\n",
    "# embeddings_model = HuggingFaceEmbeddings(\n",
    "#     model_name=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\",\n",
    "#     model_kwargs={\"device\": \"mps\"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'\n",
    "#     # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "#     encode_kwargs={\n",
    "#         \"normalize_embeddings\": True\n",
    "#     },  # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    "# )\n",
    "\n",
    "# 임베딩(Embedding) 정의\n",
    "# embeddings_model = HuggingFaceEmbeddings(\n",
    "#     model_name=\"BAAI/bge-m3\",\n",
    "#     model_kwargs={\"device\": \"mps\"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'\n",
    "#     # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "#     encode_kwargs={\n",
    "#         \"normalize_embeddings\": True\n",
    "#     },  # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    "# )\n",
    "model_name_path = '../embedding_model/BAAI_bge-m3'\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "        model_name=model_name_path, \n",
    "        model_kwargs={\"device\": \"mps\"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'\n",
    "        # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "        encode_kwargs={\n",
    "            \"normalize_embeddings\": True\n",
    "        },  # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# 1단계 : 임베딩할 파일 지정 및 PDF를 텍스트 문서로 변환\n",
    "# -------------------------------------------\n",
    "print(\"-\" * 70)\n",
    "print(f\"[{get_cur_time()}] 1단계 : 임베딩할 파일 지정 및 텍스트 문서로 변환\")\n",
    "print(\"-\" * 70)\n",
    "cur_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "# 지정한 폴더 하위의 모든 pdf, PDF 파일 조회\n",
    "# ----------------------------------\n",
    "# DOCUMENT_FOLDER = \"./data/jbb\"\n",
    "DOCUMENT_FOLDER = \"./rag_data/jbb\"\n",
    "# DOCUMENT_FOLDER = \"./data/jbb/신입행원연수_2023\"\n",
    "# DOCUMENT_FOLDER = \"./data/jbb/책임자고시_2024\"\n",
    "\n",
    "file_lists = []\n",
    "def search(dirname):\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1]\n",
    "                if ext == '.pdf' or ext == '.PDF': \n",
    "                    file_lists.append(full_filename)\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "    return file_lists\n",
    "\n",
    "pdf_files = search(DOCUMENT_FOLDER)\n",
    "pdf_files_backup = pdf_files.copy()\n",
    "\n",
    "pdf_file_tot_cnt = 0\n",
    "pdf_file_tot_page_cnt = 0\n",
    "pdf_docs = []\n",
    "\n",
    "# pdf 파일 로딩\n",
    "# -----------\n",
    "for pdf_file_cnt, pdf_file in enumerate(pdf_files):\n",
    "    # loader = PyMuPDFLoader(pdf_file)\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "\n",
    "    pdf_doc = loader.load()\n",
    "    pdf_docs.extend(pdf_doc)\n",
    "\n",
    "    # print(f\"CNT: {pdf_file_cnt+1:>3}, 페이지 수: {len(pdf_doc):>3}, 파일명: {pdf_file}\")\n",
    "    pdf_file_tot_page_cnt += len(pdf_doc)\n",
    "    pdf_file_tot_cnt += 1\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"[{get_cur_time()}] 파일의 전체 갯수 : {pdf_file_tot_cnt}, 파일의 전체 페이지 수: {pdf_file_tot_page_cnt}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "\n",
    "# 2단계 : 토큰 수를 기준으로 청크 단위로 Split\n",
    "# ------------------------------------\n",
    "# HuggingFace Embedding 모델의 Tokenizer를 사용하여 토큰화\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_path)\n",
    "# model_name_path = '../embedding_model/BAAI_bge-m3'\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"[{get_cur_time()}] PDF 문서의 페이지 수: {len(pdf_docs)}, 분할한 문서의 수: {len(split_docs)}\")\n",
    "\n",
    "\n",
    "## 일부 필요한 텍스트를 분할된 문서에 추가 및 불필요한 문자 삭제\n",
    "final_docs = []\n",
    "\n",
    "# 문서만 보여주기 위한 Document 객체 생성 및 저장\n",
    "contents = ['보여줘', '알려줘', '']\n",
    "for pdf_file_cnt, pdf_file in enumerate(pdf_files_backup):\n",
    "    for content in contents:\n",
    "        title = os.path.splitext(pdf_file)[0].split('/')[-1]    # 파일명만 추출\n",
    "        doc = Document(page_content = f\"전북은행 {title} {content}\")\n",
    "        doc.metadata['title'] = title        \n",
    "        doc.metadata['source'] = pdf_file\n",
    "        doc.metadata['page'] = 0\n",
    "        \n",
    "        final_docs.append(doc)\n",
    "\n",
    "doc_cnt = len(final_docs)   # 문서만 보여주기위한 문서 수 \n",
    "\n",
    "\n",
    "for doc in split_docs:\n",
    "    title = os.path.splitext(doc.metadata['source'])[0].split('/')[-1]\n",
    "    doc.page_content = (\n",
    "        re.sub(r\"(?<!\\.)\\n\", \" \", doc.page_content)\n",
    "        + f\"\\n\\n문서 : 전북은행 {title}\"        \n",
    "    )\n",
    "    doc.metadata['title'] = title\n",
    "    final_docs.append(doc)\n",
    "\n",
    "print(f\"[{get_cur_time()}] 분할한 문서의 수: {len(split_docs)}, 보여주기위한 문서수: {doc_cnt}, 처리할 총 문서의 수: {len(final_docs)}\")\n",
    "\n",
    "print(f\"[{get_cur_time()}] 벡터 스토어 저장 Start ...\")\n",
    "\n",
    "\n",
    "# MAXIMUN BATCH SIZE(41666) 초과에 대한 대응 코드\n",
    "# -------------------------------------------\n",
    "## ValueError: Batch size 56732 exceeds maximum batch size 41666\n",
    "## --------------------------------------------------------------\n",
    "def split_list(input_list, chunk_size):\n",
    "    for i in range(0, len(input_list), chunk_size):\n",
    "        yield input_list[i:i + chunk_size]\n",
    "        \n",
    "# split_docs_chunked = split_list(split_docs, 10000)\n",
    "split_docs_chunked = split_list(final_docs, 10000)\n",
    "\n",
    "proc_tot_cnt = 0\n",
    "for split_docs_chunk in split_docs_chunked:\n",
    "    # Chroma DB 에 저장    \n",
    "    vectorstore = Chroma.from_documents(        # 10000개씩 Chroma DB 에 저장\n",
    "        documents=split_docs_chunk,\n",
    "        embedding=embeddings_model,\n",
    "        persist_directory=\"./Chroma_db/chroma_bank_law_db\",\n",
    "        # persist_directory=\"./chroma_bank_law_db\",\n",
    "        collection_name=\"bank_law_case\",\n",
    "    )\n",
    "    proc_tot_cnt += len(split_docs_chunk)\n",
    "    print(f\"[{get_cur_time()}] Chroma DB 에 저장된 총 건수: {proc_tot_cnt}\")    \n",
    "\n",
    "print(f\"[{get_cur_time()}] 문서 임베딩이 완료 되었습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name_path = '../embedding_model/BAAI_bge-m3'\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "        model_name=model_name_path, \n",
    "        model_kwargs={\"device\": \"mps\"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'\n",
    "        # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "        encode_kwargs={\n",
    "            \"normalize_embeddings\": True\n",
    "        },  # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    "    )\n",
    "\n",
    "# vectorstore = Chroma.from_documents(documents=final_docs,\n",
    "#                                     embedding=embeddings_model,\n",
    "#                                     collection_name=\"bank_law_case\",\n",
    "#                                     persist_directory=\"./chroma_bank_law_db\")\n",
    "\n",
    "# vectorstore = Chroma(persist_directory=\"./chroma_bank_law_db\", embedding_function=embeddings_model, collection_name=\"bank_law_case\")\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"./Chroma_db/chroma_bank_law_db\", embedding_function=embeddings_model, collection_name=\"bank_law_case\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 페이지 내용 ] 39 \n",
      " 전북은행 별표 1 일반직원 본봉표 (2024. 7. 1. 개정) 알려줘\n",
      "[ 메타 데이터 ] \n",
      " ./rag_data/jbb/규정/별표 1 일반직원 본봉표 (2024. 7. 1. 개정).pdf 1\n",
      "--------------------------------------------------------------------------------\n",
      "[ 페이지 내용 ] 547 \n",
      " <별표 1> 일반직원 본봉표 (2024. 7. 1. 개정) 일반직원 본봉표 (단위 : 원)    급별  호봉7급 6급 5급 4급 3급 2급 1급 1 782,100 1,000,000 1,540,500 2,129,200 2,635,000 3,087,200 3,515,500  2 815,800 1,041,300 1,585,300 2,180,200 2,684,700 3,136,600 3,563,700  3 849,400 1,082,600 1,630,100 2,231,400 2,734,500 3,186,000 3,612,100  4 883,200 1,123,800 1,674,900 2,282,500 2,784,200 3,235,300 3,660,300  5 916,900 1,165,100 1,719,700 2,333,700 2,820,100 3,284,800 3,708,600  6 950,600 1,206,400 1,764,500 2,384,800 2,869,600 3,334,200 3,756,800\n",
      "\n",
      "문서 : 전북은행 별표 1 일반직원 본봉표 (2024. 7. 1. 개정)\n",
      "[ 메타 데이터 ] \n",
      " ./rag_data/jbb/규정/별표 1 일반직원 본봉표 (2024. 7. 1. 개정).pdf 1\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# chroma_docs = vectorstore.similarity_search(\"예금 상품의 이자계산에 대해서 알려줘\", k=5)\n",
    "# chroma_docs = vectorstore.similarity_search(\"대여금고 취급 지침에 의하면 대여금고 취급할 경우 주의 사항에 대해서 알려줘\", k=5)\n",
    "# chroma_docs = vectorstore.similarity_search(\"A1003 이사회 규정에서 정하는 이사의 권한과 의무에 대해서 알려줘\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search(\"A1003 이사회 규정에서 의장을 선임은 어떻게 해\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search(\"A1003 이사회 규정에서 의장을 선임은 어떻게 해\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search(\"전북은행 전산운영위원회지침 에서 IT투자심의 건당5천만원 알려줘.\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search(\"문서 전산운영위원회 지침에서 정하는 에서 정하는 IT투자심의 및 사후관리 건당5천만원 대해서 알려주세요.\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search(\"문서 전산운영위원회지침의 건당 5천만원 IT투자심의가 뭐야\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search(\"전산운영위원회 지침 보여줘\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search(\"복지 규정의 문화체육 활동비 내용을 알려줘\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search_with_score(\"r2045 가계자금대출 업무지침 을 보여줘\", k=1)\n",
    "# chroma_docs = vectorstore.similarity_search_with_score(\"일반 직원본봉표 보여줘\", k=5)\n",
    "# chroma_docs = vectorstore.similarity_search_with_score(\"일반 직원본봉표 보여줘\", k=2)\n",
    "chroma_docs = vectorstore.similarity_search(\"일반 직원본봉표 보여줘\", k=2)\n",
    "# chroma_docs = vectorstore.similarity_search(\"자체 보안성 검토 절차\", k=3)\n",
    "\n",
    "# for doc, score in chroma_docs:\n",
    "#     print(f'[ 페이지 내용 ] {len(doc.page_content)} score: {score}\\n {doc.page_content}')\n",
    "#     print(f'[ 메타 데이터 ] \\n {str(doc.metadata[\"source\"])} {str(int(doc.metadata[\"page\"]) + 1)}')\n",
    "#     print(\"-\" * 80)\n",
    "\n",
    "for doc in chroma_docs:\n",
    "    print(f'[ 페이지 내용 ] {len(doc.page_content)} \\n {doc.page_content}')\n",
    "    print(f'[ 메타 데이터 ] \\n {str(doc.metadata[\"source\"])} {str(int(doc.metadata[\"page\"]) + 1)}')\n",
    "    print(\"-\" * 80)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 메타 데이터 ] \n",
      " ./data/jbb/규정/(A1010) 주식규정.pdf 1\n",
      "--------------------------------------------------------------------------------\n",
      "{'source': './data/jbb/규정/(A1010) 주식규정.pdf', 'page': 0}\n",
      "[ 메타 데이터 ] \n",
      " ./data/jbb/규정/(I1002) 내부통제 규정 [개정(7) 2023. 3.15].pdf 8\n",
      "--------------------------------------------------------------------------------\n",
      "{'source': './data/jbb/규정/(I1002) 내부통제 규정 [개정(7) 2023. 3.15].pdf', 'page': 7}\n"
     ]
    }
   ],
   "source": [
    "chroma_docs = vectorstore.similarity_search_with_score(\"주식규정에 대해서 알려줘\", k=2)\n",
    "\n",
    "for doc, score in chroma_docs:\n",
    "    print(f'[ 메타 데이터 ] \\n {str(doc.metadata[\"source\"])} {str(int(doc.metadata[\"page\"]) + 1)}')\n",
    "    print(\"-\" * 80)\n",
    "    url_params = {'source': doc.metadata[\"source\"], 'page': doc.metadata[\"page\"]}\n",
    "    print(url_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일이름의 \"_\" 를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_underscores_from_filenames(directory):\n",
    "    try:\n",
    "        # List all files in the specified directory\n",
    "        for filename in os.listdir(directory):\n",
    "            # Check if the filename contains underscores\n",
    "            if '_' in filename:\n",
    "                # Create the new filename by removing underscores\n",
    "                new_filename = filename.replace('_', '')\n",
    "                # Construct the full old and new file paths\n",
    "                old_file = os.path.join(directory, filename)\n",
    "                new_file = os.path.join(directory, new_filename)\n",
    "                # Rename the file\n",
    "                os.rename(old_file, new_file)\n",
    "                print(f'Renamed: {old_file} to {new_file}')\n",
    "        print(\"All files have been renamed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "# directory_path = '/Users/netager/prod_llm/Jabis/source/data/jbb/규정'\n",
    "# directory_path = '/Users/netager/prod_llm/Jabis/source/data/jbb/신입행원연수_2023'\n",
    "# directory_path = '/Users/netager/prod_llm/Jabis/source/data/jbb/책임자고시_2024'\n",
    "directory_path = '/Users/netager/prod_llm/Jabis/source/data/jbb/IT업무매뉴얼'\n",
    "\n",
    "remove_underscores_from_filenames(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_docs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_docs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = Chroma.from_documents(documents=final_docs,\n",
    "#                                     embedding=embeddings_model,\n",
    "#                                     collection_name=\"bank_law_case\",\n",
    "#                                     persist_directory=\"./chroma_bank_law_db\")\n",
    "\n",
    "# vectorstore = Chroma(persist_directory=\"./chroma_bank_law_db\", embedding_function=embeddings_model, collection_name=\"bank_law_case\")\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"./chroma_bank_law_db\", embedding_function=embeddings_model, collection_name=\"bank_law_case\",\n",
    ")\n",
    "\n",
    "# chroma_docs = vectorstore.similarity_search(\"예금 상품의 이자계산에 대해서 알려줘\", k=5)\n",
    "# chroma_docs = vectorstore.similarity_search(\"대여금고 취급 지침에 의하면 대여금고 취급할 경우 주의 사항에 대해서 알려줘\", k=5)\n",
    "chroma_docs = vectorstore.similarity_search(\"A1003 이사회 규정에서 정하는 이사의 권한과 의무에 대해서 알려줘\", k=3)\n",
    "chroma_docs = vectorstore.similarity_search(\"A1003 이사회 규정에서 의장을 선임은 어떻게 해\", k=3)\n",
    "chroma_docs = vectorstore.similarity_search(\"A1003 이사회 규정에서 의장을 선임은 어떻게 해\", k=3)\n",
    "chroma_docs = vectorstore.similarity_search(\"전북은행 전산운영위원회지침 에서 IT투자심의 건당5천만원 알려줘.\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search(\"문서 전산운영위원회 지침에서 정하는 에서 정하는 IT투자심의 및 사후관리 건당5천만원 대해서 알려주세요.\", k=3)\n",
    "# chroma_docs = vectorstore.similarity_search(\"문서 전산운영위원회지침의 건당 5천만원 IT투자심의가 뭐야\", k=3)\n",
    "chroma_docs = vectorstore.similarity_search(\"자체 보안성 검토 절차\", k=3)\n",
    "for doc in chroma_docs:\n",
    "    print(f'[ 페이지 내용 ] \\n {doc.page_content}')\n",
    "    print(f'[ 메타 데이터 ] \\n {str(doc.metadata[\"source\"])} {str(int(doc.metadata[\"page\"]) + 1)}')\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# from tqdm.autonotebook import tqdm, trange\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Embedding 모델 정의\n",
    "# -----------------\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\",\n",
    "    model_kwargs={\"device\": \"mps\"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'\n",
    "    # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "    encode_kwargs={\n",
    "        \"normalize_embeddings\": True\n",
    "    },  # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    ")\n",
    "\n",
    "\n",
    "# 1단계 : 임베딩할 파일 지정 및 PDF를 텍스트 문서로 변환\n",
    "# -------------------------------------------\n",
    "print(\"-\" * 60)\n",
    "print(\"1단계 : 임베딩할 파일 지정 및 텍스트 문서로 변환\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# PyMuPDFLoader\n",
    "# -------------\n",
    "# loader = PyMuPDFLoader(\"../data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "# loader = PyMuPDFLoader(\"../data/전자금융감독규정(금융위원회고시)(제2022-44호)(20230101).pdf\")\n",
    "\n",
    "# PyPDFLoader\n",
    "# -----------\n",
    "# loader = PyPDFLoader(\"../data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "# loader = PyPDFLoader(\"../data/전자금융감독규정(금융위원회고시)(제2022-44호)(20230101).pdf\")\n",
    "\n",
    "# UnstructuredPDFLoader\n",
    "# ---------------------\n",
    "# loader = UnstructuredPDFLoader(\"../data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "# loader = UnstructuredPDFLoader(\"../data/전자금융감독규정(금융위원회고시)(제2022-44호)(20230101).pdf\")\n",
    "\n",
    "# PyPDFDirectoryLoader\n",
    "# --------------------\n",
    "# loader = PyPDFDirectoryLoader(\"./data/fss/\")\n",
    "# loader = PyPDFDirectoryLoader(\"./data/jbb/매뉴얼/\")\n",
    "# docs = loader.load()\n",
    "\n",
    "# pdf_files = glob(os.path.join('./data/fss', '*.pdf'))\n",
    "# pdf_files = glob(os.path.join('./data/jbb/규정', '*.pdf'))\n",
    "# pdf_files = glob(os.path.join('./data/jbb/지침', '*.pdf'))\n",
    "# pdf_files = glob(os.path.join(\"./data/jbb/매뉴얼\", \"*.pdf\"))\n",
    "# pdf_files = glob(os.path.join(\"./data/jbb/신입행원연수_2023\", \"*.pdf\"))\n",
    "pdf_files = glob(os.path.join(\"./data/jbb/책임자고시_2024\", \"*.pdf\"))\n",
    "\n",
    "\n",
    "pdf_file_tot_cnt = 0\n",
    "pdf_file_tot_page_cnt = 0\n",
    "pdf_docs = []\n",
    "\n",
    "for pdf_file_cnt, pdf_file in enumerate(pdf_files):\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    # loader = PyMuPDFLoader(pdf_file)\n",
    "    pdf_doc = loader.load()\n",
    "    pdf_docs.extend(pdf_doc)\n",
    "\n",
    "    print(f\"CNT: {pdf_file_cnt+1:>3}, 페이지 수: {len(pdf_doc):>3}, 파일명: {pdf_file}\")\n",
    "    pdf_file_tot_page_cnt += len(pdf_doc)\n",
    "    pdf_file_tot_cnt += 1\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\n",
    "    f\"파일의 전체 갯수 : {pdf_file_tot_cnt}, 파일의 전체 페이지 수: {pdf_file_tot_page_cnt}\"\n",
    ")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# 2단계 : 토큰 수를 기준으로 청크 단위로 Split\n",
    "# ------------------------------------\n",
    "# HuggingFace Embedding 모델의 Tokenizer를 사용하여 토큰화\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=40,\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"PDF 문서의 페이지 수: {len(pdf_docs)}, 분할한 문서의 수: {len(split_docs)}\")\n",
    "\n",
    "\n",
    "## 일부 필요한 텍스트를 분할된 문서에 추가 및 불필요한 문자 삭제\n",
    "final_docs = []\n",
    "\n",
    "for doc in split_docs:\n",
    "    doc.page_content = (\n",
    "       f\"### 이 문서는 '{doc.metadata['source']}' 파일의 {int(doc.metadata['page'])+1} 페이지에 있습니다.\\n\\n\"\n",
    "        + re.sub(r\"(?<!\\.)\\n\", \" \", doc.page_content)\n",
    "        # re.sub(r\"(?<!\\.)\\n\", \" \", doc.page_content)\n",
    "    )\n",
    "    final_docs.append(doc)\n",
    "\n",
    "\n",
    "# 벡터 스토어 저장\n",
    "#collection_name=\"bank_law_case\",\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents=final_docs,\n",
    "#     embedding=embeddings_model,\n",
    "#     persist_directory=\"./chroma_bank_law_db\",\n",
    "# )\n",
    "\n",
    "print(f\"문서 임베딩이 완료 되었습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5},\n",
    ")\n",
    "\n",
    "query = \"삼성에서 개발한 AI의 이름은?\"\n",
    "# query = f\"그룹공동 데이터베이스의 구축 및 운영시 암호화에 대해서 알려주세요.\"\n",
    "# query = f\"전산운영위원회에서 정하는 심의 조정에 대해서 알려주세요.\"\n",
    "\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(\n",
    "        str(doc.metadata[\"source\"]), str(doc.metadata[\"page\"]), doc.page_content[:200]\n",
    "    )\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# RAG Chain\n",
    "llm = ChatOllama(model=\"qwen2-7b-instruct-q8:latest\", temperature=0)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "# query = f\"인공지능의 미래 또는 발전 방향에 대해서 알려주세요.\"\n",
    "# query = f\"삼성전자가 개발한 인공지능 AI의 이름은?\"\n",
    "# query = f\"고객정보의 제공 및 관리규정에서 말하는 개인신용정보에 대해서 알려주세요\"\n",
    "# query = f\"그룹공동 데이터베이스의 구축 및 운영시 암호화에 대해서 알려주세요.\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwagrs={\n",
    "        \"k\": 2,\n",
    "    }\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = rag_chain.stream(query)\n",
    "for res in response:\n",
    "    print(res, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분할본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from tqdm.autonotebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단계 1: 문서 로드(Load Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 1: 문서 로드(Load Documents)\n",
    "\n",
    "# PyMuPDFLoader\n",
    "# -------------\n",
    "# loader = PyMuPDFLoader(\"../data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "# loader = PyMuPDFLoader(\"../data/전자금융감독규정(금융위원회고시)(제2022-44호)(20230101).pdf\")\n",
    "\n",
    "# PyPDFLoader\n",
    "# -----------\n",
    "# loader = PyPDFLoader(\"../data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "# loader = PyPDFLoader(\"../data/전자금융감독규정(금융위원회고시)(제2022-44호)(20230101).pdf\")\n",
    "\n",
    "# UnstructuredPDFLoader\n",
    "# ---------------------\n",
    "# loader = UnstructuredPDFLoader(\"../data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "# loader = UnstructuredPDFLoader(\"../data/전자금융감독규정(금융위원회고시)(제2022-44호)(20230101).pdf\")\n",
    "\n",
    "# PyPDFDirectoryLoader\n",
    "# --------------------\n",
    "# loader = PyPDFDirectoryLoader(\"./data/fss/\")\n",
    "# loader = PyPDFDirectoryLoader(\"./data/jbb/매뉴얼/\")\n",
    "# docs = loader.load()\n",
    "\n",
    "# Multi PyMuPDF Loader\n",
    "# ---------------------\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# pdf_files = glob(os.path.join('./data/jbb/지침', '*.pdf'))\n",
    "# pdf_files = glob(os.path.join('./data/fss', '*.pdf'))\n",
    "pdf_files = glob(os.path.join(\"./data/jbb/매뉴얼\", \"*.pdf\"))\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"1단계 : 임베딩할 파일 지정 및 로딩\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "pdf_file_tot_cnt = 0\n",
    "for pdf_file_cnt, pdf_file in enumerate(pdf_files):\n",
    "    print(f\"파일 No: {pdf_file_cnt+1:>3}, 파일명: {pdf_file}\")\n",
    "    pdf_file_tot_cnt += 1\n",
    "print(\"-\" * 60)\n",
    "print(f\"파일의 전체 갯수 : {pdf_file_tot_cnt}\")\n",
    "print(\"-\" * 60)\n",
    "# print(f\"문서의 수: {len(docs)}\\n\")\n",
    "# print(\"[메타데이터]\\n\")\n",
    "# print(docs[010].metadata)\n",
    "# print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
    "# print(docs[10].page_content[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf 파일을 읽어서 텍스트로 변환\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "pdf_docs = []\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyMuPDFLoader(pdf_file)\n",
    "    pdf_doc = loader.load()\n",
    "    pdf_docs.extend(pdf_doc)\n",
    "\n",
    "    print(f\"페이지 수: {len(pdf_doc)}, 파일명: {pdf_file}\")\n",
    "\n",
    "# print(f\"문서의 수: {len(pdf_docs)}\\n\")  # 문서의 페이지 수\n",
    "# print(\"[메타데이터]\\n\")\n",
    "# print(pdf_docs[0].metadata)\n",
    "# print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
    "# print(data[0].page_content[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=\"BAAI/bge-m3\",\n",
    "#     model_kwargs={\"device\": \"mps\"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'\n",
    "#     # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "#     encode_kwargs={\n",
    "#         \"normalize_embeddings\": True\n",
    "#     },  # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    "# )\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\",\n",
    "    model_kwargs={\"device\": \"mps\"},  # cpu : 'cpu', macOS: 'mps', CUDA: 'cuda'\n",
    "    # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "    encode_kwargs={\n",
    "        \"normalize_embeddings\": True\n",
    "    },  # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"온라인 쇼핑몰에서 주문한 제품이 불량품으로 배송되었습니다. 이에 대한 법적 책임은 누구에게 있나요?\",\n",
    "        \"구입한 전자제품이 고장나서 환불을 요청했지만 거부당했습니다. 피해 보상을 받을 수 있나요?\",\n",
    "        \"호텔 예약 후 도착했는데 예약이 취소되었다고 했습니다. 이에 대한 대응 방법은 무었인가요?\",\n",
    "        \"자동차 수리 후 동일한 문제가 재발했습니다. 수리업체에 대한 법적 조치를 취할 수 있나요?\",\n",
    "        \"항공편이 지연되어 중요한 일정을 놓쳤습니다. 이에 대한 피해 보상을 받을 수 있나요?\",\n",
    "    ]\n",
    ")\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query = embeddings_model.embed_query(\n",
    "    \"에어컨 제품 불량에 대해서 보상 받을 수 있을까요?\"\n",
    ")\n",
    "embedded_query[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 2: 문서 분할(Split Documents)\n",
    "# Token 수를 기준으로 문서를 청크 단위로 분할\n",
    "# HuggingFace Embedding 모델의 Tokenizer를 사용하여 토큰화\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "pdf_docs = data\n",
    "split_docs = text_splitter.split_documents(pdf_docs)\n",
    "print(\"pdf 문서수: \", len(pdf_docs), \"split 문서수: \", len(split_docs))\n",
    "# print(split_docs[0].page_content)\n",
    "# type(split_docs[0])\n",
    "total = 0\n",
    "for i in range(5):\n",
    "    print(\n",
    "        f\"{i} 문서의 문자수 : {len(split_docs[i].page_content)} 토큰 갯수 : {len(tokenizer.encode(split_docs[i].page_content))}\"\n",
    "    )\n",
    "    total = i + 1\n",
    "    if total > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "final_docs = []\n",
    "\n",
    "for doc in split_docs:\n",
    "    doc.page_content = (\n",
    "        f\"### 이 문서는 '{doc.metadata['source']}' 파일의 {int(doc.metadata['page'])+1} 페이지에 있습니다.\\n\\n\"\n",
    "        + re.sub(r\"(?<!\\.)\\n\", \" \", doc.page_content)\n",
    "    )\n",
    "    final_docs.append(doc)\n",
    "\n",
    "print(final_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma DB 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=final_docs,\n",
    "    embedding=embeddings_model,\n",
    "    collection_name=\"bank_law_case\",\n",
    "    persist_directory=\"./chroma_bank_law_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_docs = vectorstore.similarity_search(\"삼성에서 개발한 AI의 이름은?\", k=5)\n",
    "# chroma_docs = vectorstore.similarity_search(\"전산운영위원회에서 정하는 IT투자심의 및 사후관리 건당5천만원 대해서 알려주세요.\", k=5)\n",
    "chroma_docs = vectorstore.similarity_search(\"삼성전자가 개발한 AI의 이름은?\", k=1)\n",
    "for doc in chroma_docs:\n",
    "    print(\n",
    "        str(doc.metadata[\"source\"]),\n",
    "        str(int(doc.metadata[\"page\"]) + 1),\n",
    "        doc.page_content[:200],\n",
    "    )\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5},\n",
    ")\n",
    "\n",
    "# query = \"삼성에서 개발한 AI의 이름은?\"\n",
    "# query = f\"그룹공동 데이터베이스의 구축 및 운영시 암호화에 대해서 알려주세요.\"\n",
    "query = f\"전산운영위원회에서 정하는 심의 조정에 대해서 알려주세요.\"\n",
    "\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(\n",
    "        str(doc.metadata[\"source\"]), str(doc.metadata[\"page\"]), doc.page_content[:200]\n",
    "    )\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generateion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG 생성 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Chain\n",
    "llm = ChatOllama(model=\"qwen2-7b-instruct-q8:latest\", temperature=0)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "# query = f\"인공지능의 미래 또는 발전 방향에 대해서 알려주세요.\"\n",
    "query = f\"삼성전자가 개발한 인공지능 AI의 이름은?\"\n",
    "# query = f\"고객정보의 제공 및 관리규정에서 말하는 개인신용정보에 대해서 알려주세요\"\n",
    "# query = f\"그룹공동 데이터베이스의 구축 및 운영시 암호화에 대해서 알려주세요.\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwagrs={\n",
    "        \"k\": 2,\n",
    "    }\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = rag_chain.stream(query)\n",
    "for res in response:\n",
    "    print(res, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 기존 사진 백업 필수!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# 기존에 있는 사진들을 삭제됨\n",
    "\n",
    "# 기존 파일 경로\n",
    "folder_path = \"./data/jbb/매뉴얼\"\n",
    "\n",
    "# 새로 저장 경로 (정확히 맞아야 함)\n",
    "dst_path = \"./data/jbb/매뉴얼\"\n",
    "\n",
    "# 폴더안에있는 파일들 이름 리스트로 가져오기\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "print(file_names)\n",
    "# 확인\n",
    "\n",
    "for file in file_names:\n",
    "    f_name, f_format = file.split(sep=\".P\")  # 파일 이름, 파일 확장자 split\n",
    "    # print(f_name, f_format)\n",
    "\n",
    "    src_file = os.path.join(folder_path, file)\n",
    "    dest_file = os.path.join(folder_path, f_name + \".pdf\")\n",
    "\n",
    "    print(\"rename\" + file + \" to \" + dest_file)\n",
    "    os.rename(src_file, dest_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prod_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
